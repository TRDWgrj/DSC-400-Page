{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de9045ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global imports\n",
    "\n",
    "from collections import defaultdict\n",
    "import string\n",
    "from operator import add\n",
    "from functools import reduce\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6600746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"\n",
    "    Well, the way they make shows is, they make one show. \n",
    "    That show's called a pilot. \n",
    "    Then they show that show to the people who make shows, \n",
    "    and on the strength of that one show they decide \n",
    "    if they're going to make more shows. Some pilots \n",
    "    get picked and become television programs. \n",
    "    Some don't, become nothing. \n",
    "    She starred in one of the ones that became nothing.\n",
    "\"\"\"\n",
    "\n",
    "text2 = \"\"\"\n",
    "    You think water moves fast? You should see ice. \n",
    "    It moves like it has a mind. \n",
    "    Like it knows it killed the world once and got a taste for murder. \n",
    "    After the avalanche, it took us a week to climb out. \n",
    "    Now, I don't know exactly when we turned on each other, \n",
    "    but I know that seven of us survived the slide... \n",
    "    and only five made it out. Now we took an oath, that I'm breaking now. \n",
    "    We said we'd say it was the snow that killed the other two, but it wasn't. \n",
    "    Nature is lethal but it doesn't hold a candle to man.\n",
    "\"\"\"\n",
    "\n",
    "text3 = \"\"\"\n",
    "    Now that we know who you are, I know who I am. I'm not a mistake! \n",
    "    It all makes sense! In a comic, you know how you can tell who the arch-villain's going to be? \n",
    "    He's the exact opposite of the hero. And most times they're friends, like you and me! \n",
    "    I should've known way back when... You know why, David? Because of the kids. \n",
    "    They called me Mr Glass.\n",
    "\"\"\"\n",
    "\n",
    "text4 = \"\"\"\n",
    "    Your bones don't break, mine do. That's clear. \n",
    "    Your cells react to bacteria and viruses differently than mine. \n",
    "    You don't get sick, I do. That's also clear. \n",
    "    But for some reason, you and I react the exact same way to water. \n",
    "    We swallow it too fast, we choke. We get some in our lungs, we drown. \n",
    "    However unreal it may seem, we are connected, you and I. \n",
    "    We're on the same curve, just on opposite ends.\n",
    "\"\"\"\n",
    "\n",
    "documents = [text1, text2, text3, text4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4212cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Simple function to remove punctuation from text\n",
    "\n",
    "    :param text: text to remove punctuation from\n",
    "    :return: text with punctuation removed\n",
    "    \"\"\"\n",
    "    return ''.join([\n",
    "        character\n",
    "        for character in text\n",
    "        if character not in string.punctuation\n",
    "    ])\n",
    "\n",
    "def word_count_map_function(text: str) -> list[tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Simple map function that takes text and outputs tuples\n",
    "    of words and counts\n",
    "    \n",
    "    :param text: text to convert into word/count tuples\n",
    "    :return: A list of tuples with word and count\n",
    "    \"\"\"\n",
    "    # TODO: Implement the word count map function\n",
    "\n",
    "    # Step 1: Remove punctuation from text\n",
    "    text = remove_punctuation(text)\n",
    "    # Step 2: Convert text to lower case\n",
    "    text = text.lower()\n",
    "    # Step 3: Split the text by spaces to convert into words\n",
    "    text = text.split()\n",
    "    # Step 4: Return a list containing word/count tuple pairs\n",
    "    \n",
    "    # Removes duplicates\n",
    "    words = list(set(text))    \n",
    "    # Creates list containing word/count tuple pairs\n",
    "    word_count_pairs = []\n",
    "    for word in words:\n",
    "        word_count_pairs.append((word, text.count(word)))\n",
    "\n",
    "    return sorted(word_count_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64a87483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('a', 1),\n",
       "  ('and', 2),\n",
       "  ('became', 1),\n",
       "  ('become', 2),\n",
       "  ('called', 1),\n",
       "  ('decide', 1),\n",
       "  ('dont', 1),\n",
       "  ('get', 1),\n",
       "  ('going', 1),\n",
       "  ('if', 1),\n",
       "  ('in', 1),\n",
       "  ('is', 1),\n",
       "  ('make', 4),\n",
       "  ('more', 1),\n",
       "  ('nothing', 2),\n",
       "  ('of', 2),\n",
       "  ('on', 1),\n",
       "  ('one', 3),\n",
       "  ('ones', 1),\n",
       "  ('people', 1),\n",
       "  ('picked', 1),\n",
       "  ('pilot', 1),\n",
       "  ('pilots', 1),\n",
       "  ('programs', 1),\n",
       "  ('she', 1),\n",
       "  ('show', 4),\n",
       "  ('shows', 4),\n",
       "  ('some', 2),\n",
       "  ('starred', 1),\n",
       "  ('strength', 1),\n",
       "  ('television', 1),\n",
       "  ('that', 4),\n",
       "  ('the', 4),\n",
       "  ('then', 1),\n",
       "  ('they', 4),\n",
       "  ('theyre', 1),\n",
       "  ('to', 2),\n",
       "  ('way', 1),\n",
       "  ('well', 1),\n",
       "  ('who', 1)],\n",
       " [('a', 4),\n",
       "  ('after', 1),\n",
       "  ('an', 1),\n",
       "  ('and', 2),\n",
       "  ('avalanche', 1),\n",
       "  ('breaking', 1),\n",
       "  ('but', 3),\n",
       "  ('candle', 1),\n",
       "  ('climb', 1),\n",
       "  ('doesnt', 1),\n",
       "  ('dont', 1),\n",
       "  ('each', 1),\n",
       "  ('exactly', 1),\n",
       "  ('fast', 1),\n",
       "  ('five', 1),\n",
       "  ('for', 1),\n",
       "  ('got', 1),\n",
       "  ('has', 1),\n",
       "  ('hold', 1),\n",
       "  ('i', 2),\n",
       "  ('ice', 1),\n",
       "  ('im', 1),\n",
       "  ('is', 1),\n",
       "  ('it', 9),\n",
       "  ('killed', 2),\n",
       "  ('know', 2),\n",
       "  ('knows', 1),\n",
       "  ('lethal', 1),\n",
       "  ('like', 2),\n",
       "  ('made', 1),\n",
       "  ('man', 1),\n",
       "  ('mind', 1),\n",
       "  ('moves', 2),\n",
       "  ('murder', 1),\n",
       "  ('nature', 1),\n",
       "  ('now', 3),\n",
       "  ('oath', 1),\n",
       "  ('of', 1),\n",
       "  ('on', 1),\n",
       "  ('once', 1),\n",
       "  ('only', 1),\n",
       "  ('other', 2),\n",
       "  ('out', 2),\n",
       "  ('said', 1),\n",
       "  ('say', 1),\n",
       "  ('see', 1),\n",
       "  ('seven', 1),\n",
       "  ('should', 1),\n",
       "  ('slide', 1),\n",
       "  ('snow', 1),\n",
       "  ('survived', 1),\n",
       "  ('taste', 1),\n",
       "  ('that', 3),\n",
       "  ('the', 5),\n",
       "  ('think', 1),\n",
       "  ('to', 2),\n",
       "  ('took', 2),\n",
       "  ('turned', 1),\n",
       "  ('two', 1),\n",
       "  ('us', 2),\n",
       "  ('was', 1),\n",
       "  ('wasnt', 1),\n",
       "  ('water', 1),\n",
       "  ('we', 3),\n",
       "  ('wed', 1),\n",
       "  ('week', 1),\n",
       "  ('when', 1),\n",
       "  ('world', 1),\n",
       "  ('you', 2)],\n",
       " [('a', 2),\n",
       "  ('all', 1),\n",
       "  ('am', 1),\n",
       "  ('and', 2),\n",
       "  ('archvillains', 1),\n",
       "  ('are', 1),\n",
       "  ('back', 1),\n",
       "  ('be', 1),\n",
       "  ('because', 1),\n",
       "  ('called', 1),\n",
       "  ('can', 1),\n",
       "  ('comic', 1),\n",
       "  ('david', 1),\n",
       "  ('exact', 1),\n",
       "  ('friends', 1),\n",
       "  ('glass', 1),\n",
       "  ('going', 1),\n",
       "  ('hero', 1),\n",
       "  ('hes', 1),\n",
       "  ('how', 1),\n",
       "  ('i', 3),\n",
       "  ('im', 1),\n",
       "  ('in', 1),\n",
       "  ('it', 1),\n",
       "  ('kids', 1),\n",
       "  ('know', 4),\n",
       "  ('known', 1),\n",
       "  ('like', 1),\n",
       "  ('makes', 1),\n",
       "  ('me', 2),\n",
       "  ('mistake', 1),\n",
       "  ('most', 1),\n",
       "  ('mr', 1),\n",
       "  ('not', 1),\n",
       "  ('now', 1),\n",
       "  ('of', 2),\n",
       "  ('opposite', 1),\n",
       "  ('sense', 1),\n",
       "  ('shouldve', 1),\n",
       "  ('tell', 1),\n",
       "  ('that', 1),\n",
       "  ('the', 4),\n",
       "  ('they', 1),\n",
       "  ('theyre', 1),\n",
       "  ('times', 1),\n",
       "  ('to', 1),\n",
       "  ('way', 1),\n",
       "  ('we', 1),\n",
       "  ('when', 1),\n",
       "  ('who', 3),\n",
       "  ('why', 1),\n",
       "  ('you', 5)],\n",
       " [('also', 1),\n",
       "  ('and', 3),\n",
       "  ('are', 1),\n",
       "  ('bacteria', 1),\n",
       "  ('bones', 1),\n",
       "  ('break', 1),\n",
       "  ('but', 1),\n",
       "  ('cells', 1),\n",
       "  ('choke', 1),\n",
       "  ('clear', 2),\n",
       "  ('connected', 1),\n",
       "  ('curve', 1),\n",
       "  ('differently', 1),\n",
       "  ('do', 2),\n",
       "  ('dont', 2),\n",
       "  ('drown', 1),\n",
       "  ('ends', 1),\n",
       "  ('exact', 1),\n",
       "  ('fast', 1),\n",
       "  ('for', 1),\n",
       "  ('get', 2),\n",
       "  ('however', 1),\n",
       "  ('i', 3),\n",
       "  ('in', 1),\n",
       "  ('it', 2),\n",
       "  ('just', 1),\n",
       "  ('lungs', 1),\n",
       "  ('may', 1),\n",
       "  ('mine', 2),\n",
       "  ('on', 2),\n",
       "  ('opposite', 1),\n",
       "  ('our', 1),\n",
       "  ('react', 2),\n",
       "  ('reason', 1),\n",
       "  ('same', 2),\n",
       "  ('seem', 1),\n",
       "  ('sick', 1),\n",
       "  ('some', 2),\n",
       "  ('swallow', 1),\n",
       "  ('than', 1),\n",
       "  ('thats', 2),\n",
       "  ('the', 2),\n",
       "  ('to', 2),\n",
       "  ('too', 1),\n",
       "  ('unreal', 1),\n",
       "  ('viruses', 1),\n",
       "  ('water', 1),\n",
       "  ('way', 1),\n",
       "  ('we', 5),\n",
       "  ('were', 1),\n",
       "  ('you', 3),\n",
       "  ('your', 2)]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_word_counts = list(map(word_count_map_function, documents))\n",
    "documents_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04aff511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_lists_reduce_function(x, y):\n",
    "    return x + y\n",
    "\n",
    "def word_count_reduce_function(key_value_pairs):\n",
    "    result = dict()\n",
    "    \n",
    "    # TODO: Implement code to return dictionary containing word/count dictionary\n",
    "    for word, count in key_value_pairs:\n",
    "        \n",
    "        if word in result:\n",
    "            result[word] += count\n",
    "        else:\n",
    "            result[word] = count\n",
    "    \n",
    "    return sorted(result.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59fdd844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 7),\n",
       " ('after', 1),\n",
       " ('all', 1),\n",
       " ('also', 1),\n",
       " ('am', 1),\n",
       " ('an', 1),\n",
       " ('and', 9),\n",
       " ('archvillains', 1),\n",
       " ('are', 2),\n",
       " ('avalanche', 1),\n",
       " ('back', 1),\n",
       " ('bacteria', 1),\n",
       " ('be', 1),\n",
       " ('became', 1),\n",
       " ('because', 1),\n",
       " ('become', 2),\n",
       " ('bones', 1),\n",
       " ('break', 1),\n",
       " ('breaking', 1),\n",
       " ('but', 4),\n",
       " ('called', 2),\n",
       " ('can', 1),\n",
       " ('candle', 1),\n",
       " ('cells', 1),\n",
       " ('choke', 1),\n",
       " ('clear', 2),\n",
       " ('climb', 1),\n",
       " ('comic', 1),\n",
       " ('connected', 1),\n",
       " ('curve', 1),\n",
       " ('david', 1),\n",
       " ('decide', 1),\n",
       " ('differently', 1),\n",
       " ('do', 2),\n",
       " ('doesnt', 1),\n",
       " ('dont', 4),\n",
       " ('drown', 1),\n",
       " ('each', 1),\n",
       " ('ends', 1),\n",
       " ('exact', 2),\n",
       " ('exactly', 1),\n",
       " ('fast', 2),\n",
       " ('five', 1),\n",
       " ('for', 2),\n",
       " ('friends', 1),\n",
       " ('get', 3),\n",
       " ('glass', 1),\n",
       " ('going', 2),\n",
       " ('got', 1),\n",
       " ('has', 1),\n",
       " ('hero', 1),\n",
       " ('hes', 1),\n",
       " ('hold', 1),\n",
       " ('how', 1),\n",
       " ('however', 1),\n",
       " ('i', 8),\n",
       " ('ice', 1),\n",
       " ('if', 1),\n",
       " ('im', 2),\n",
       " ('in', 3),\n",
       " ('is', 2),\n",
       " ('it', 12),\n",
       " ('just', 1),\n",
       " ('kids', 1),\n",
       " ('killed', 2),\n",
       " ('know', 6),\n",
       " ('known', 1),\n",
       " ('knows', 1),\n",
       " ('lethal', 1),\n",
       " ('like', 3),\n",
       " ('lungs', 1),\n",
       " ('made', 1),\n",
       " ('make', 4),\n",
       " ('makes', 1),\n",
       " ('man', 1),\n",
       " ('may', 1),\n",
       " ('me', 2),\n",
       " ('mind', 1),\n",
       " ('mine', 2),\n",
       " ('mistake', 1),\n",
       " ('more', 1),\n",
       " ('most', 1),\n",
       " ('moves', 2),\n",
       " ('mr', 1),\n",
       " ('murder', 1),\n",
       " ('nature', 1),\n",
       " ('not', 1),\n",
       " ('nothing', 2),\n",
       " ('now', 4),\n",
       " ('oath', 1),\n",
       " ('of', 5),\n",
       " ('on', 4),\n",
       " ('once', 1),\n",
       " ('one', 3),\n",
       " ('ones', 1),\n",
       " ('only', 1),\n",
       " ('opposite', 2),\n",
       " ('other', 2),\n",
       " ('our', 1),\n",
       " ('out', 2),\n",
       " ('people', 1),\n",
       " ('picked', 1),\n",
       " ('pilot', 1),\n",
       " ('pilots', 1),\n",
       " ('programs', 1),\n",
       " ('react', 2),\n",
       " ('reason', 1),\n",
       " ('said', 1),\n",
       " ('same', 2),\n",
       " ('say', 1),\n",
       " ('see', 1),\n",
       " ('seem', 1),\n",
       " ('sense', 1),\n",
       " ('seven', 1),\n",
       " ('she', 1),\n",
       " ('should', 1),\n",
       " ('shouldve', 1),\n",
       " ('show', 4),\n",
       " ('shows', 4),\n",
       " ('sick', 1),\n",
       " ('slide', 1),\n",
       " ('snow', 1),\n",
       " ('some', 4),\n",
       " ('starred', 1),\n",
       " ('strength', 1),\n",
       " ('survived', 1),\n",
       " ('swallow', 1),\n",
       " ('taste', 1),\n",
       " ('television', 1),\n",
       " ('tell', 1),\n",
       " ('than', 1),\n",
       " ('that', 8),\n",
       " ('thats', 2),\n",
       " ('the', 15),\n",
       " ('then', 1),\n",
       " ('they', 5),\n",
       " ('theyre', 2),\n",
       " ('think', 1),\n",
       " ('times', 1),\n",
       " ('to', 7),\n",
       " ('too', 1),\n",
       " ('took', 2),\n",
       " ('turned', 1),\n",
       " ('two', 1),\n",
       " ('unreal', 1),\n",
       " ('us', 2),\n",
       " ('viruses', 1),\n",
       " ('was', 1),\n",
       " ('wasnt', 1),\n",
       " ('water', 2),\n",
       " ('way', 3),\n",
       " ('we', 9),\n",
       " ('wed', 1),\n",
       " ('week', 1),\n",
       " ('well', 1),\n",
       " ('were', 1),\n",
       " ('when', 2),\n",
       " ('who', 4),\n",
       " ('why', 1),\n",
       " ('world', 1),\n",
       " ('you', 10),\n",
       " ('your', 2)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Apply the `word_count_map_function` to each the documents\n",
    "map_output_values = map(word_count_map_function, documents)\n",
    "\n",
    "# Step 2: Merge the outputs of the map function into a single list\n",
    "merged_output_values = reduce(merge_lists_reduce_function, map_output_values)\n",
    "\n",
    "# Step 3: Apply the `word_count_reduce_function` to create a single word/count dictionary\n",
    "counted_words_dict = word_count_reduce_function(merged_output_values)\n",
    "\n",
    "counted_words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fc6581",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3052dd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\12162\\anaconda3\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in c:\\users\\12162\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\12162\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a473432c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\12162\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ba3d200",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7744/642267264.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mspark\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DSC 400 Assignment 3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\sql\\session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    267\u001b[0m                         \u001b[0msparkConf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m                     \u001b[1;31m# This SparkContext may be an existing one.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m                     \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m                     \u001b[1;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m                     \u001b[1;31m# by all sessions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    481\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 483\u001b[1;33m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    484\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls)\u001b[0m\n\u001b[0;32m    193\u001b[0m             )\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             self._do_init(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"DSC 400 Assignment 3\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark_context = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec524193",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark_context' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7744/3973459526.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdocuments_rdd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of Partitions: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments_rdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetNumPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark_context' is not defined"
     ]
    }
   ],
   "source": [
    "documents_rdd = spark_context.parallelize(documents)\n",
    "\n",
    "print(\"Number of Partitions: \"+str(documents_rdd.getNumPartitions()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e874f6a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'documents_rdd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7744/1289178034.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdocuments_rdd_collect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdocuments_rdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments_rdd_collect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'documents_rdd' is not defined"
     ]
    }
   ],
   "source": [
    "documents_rdd_collect = documents_rdd.collect()\n",
    "print(documents_rdd_collect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56a739ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'documents_rdd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7744/897453898.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmap_output_rdd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdocuments_rdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatMap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_count_map_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmap_output_rdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'documents_rdd' is not defined"
     ]
    }
   ],
   "source": [
    "map_output_rdd = documents_rdd.flatMap(word_count_map_function)\n",
    "map_output_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "345a1ba0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'map_output_rdd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7744/1287646831.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_count_rdd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_output_rdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduceByKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mword_count_rdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'map_output_rdd' is not defined"
     ]
    }
   ],
   "source": [
    "word_count_rdd = map_output_rdd.reduceByKey(add)\n",
    "word_count_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f5888c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_count_rdd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7744/1808709372.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Test if both method's returns are equal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_count_rdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcounted_words_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'word_count_rdd' is not defined"
     ]
    }
   ],
   "source": [
    "# Test if both method's returns are equal\n",
    "sorted(word_count_rdd.collect()) == counted_words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5c879e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_count_rdd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7744/3756963236.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# TODO: Calculate `counts_gt_four_rdd` from `word_count_rdd`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcounts_gt_four_rdd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_count_rdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcounts_gt_four_rdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_count_rdd' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Calculate `counts_gt_four_rdd` from `word_count_rdd`\n",
    "counts_gt_four_rdd = word_count_rdd.filter(lambda x: x[1] > 4)\n",
    "counts_gt_four_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "878c7672",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_count_rdd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7744/429117562.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# TODO: Calculate `sorted_word_count_rdd` from `word_count_rdd`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msorted_word_count_rdd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_count_rdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msortBy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msorted_word_count_rdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_count_rdd' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Calculate `sorted_word_count_rdd` from `word_count_rdd`\n",
    "sorted_word_count_rdd = word_count_rdd.sortBy(lambda x: x[1], ascending=False)\n",
    "sorted_word_count_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dec9fcb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7744/3397070628.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mword_count_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"word\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"count\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m word_count_df = spark.createDataFrame(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_count_rdd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_count_columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "word_count_columns = [\"word\", \"count\"]\n",
    "word_count_df = spark.createDataFrame(\n",
    "    data=word_count_rdd, \n",
    "    schema=word_count_columns\n",
    ")\n",
    "word_count_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e0048b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_count_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7744/2653778312.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_count_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'word_count_df' is not defined"
     ]
    }
   ],
   "source": [
    "word_count_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98edb4df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_count_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7744/4190034870.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# TODO: Create `word_count_filtered` from `word_count_df`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mword_count_filtered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_count_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'count > 4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mword_count_filtered\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_count_df' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Create `word_count_filtered` from `word_count_df`\n",
    "\n",
    "word_count_filtered = word_count_df.filter('count > 4')\n",
    "word_count_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81556400",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_count_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7744/672538484.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# TODO: Create `word_count_sorted` from `word_count_df`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mword_count_sorted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_count_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mword_count_sorted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_count_df' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Create `word_count_sorted` from `word_count_df`\n",
    "\n",
    "word_count_sorted = word_count_df.sort('count', ascending=False)\n",
    "word_count_sorted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7adf1793",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_count_sorted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7744/4091841954.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# TODO: Create `word_count_top_10` from `word_count_sorted`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mword_count_top_10\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_count_sorted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mword_count_top_10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_count_sorted' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Create `word_count_top_10` from `word_count_sorted`\n",
    "\n",
    "word_count_top_10 = word_count_sorted.limit(10)\n",
    "word_count_top_10.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
