{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2dd6dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ListItem:\n",
    "    name:str\n",
    "    website:str\n",
    "    category:str\n",
    "    short_description:str\n",
    "        \n",
    "all_items = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55b9c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws = ListItem(\n",
    "    'Amazon Web Services',\n",
    "    'https://aws.amazon.com/', \n",
    "    'Cloud and Data Platforms', \n",
    "    \"\"\"Provides on-demand cloud computing platforms and API's to individuals, \n",
    "    companies, and governments, on a metered pay as you go basis.\"\"\"\n",
    ")\n",
    "\n",
    "all_items.add(aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c310f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_items.remove(aws)\n",
    "all_items.add(ListItem(\n",
    "    'Amazon Web Services',\n",
    "    'https://aws.amazon.com/', \n",
    "    'Cloud and Data Platforms', \n",
    "    \"\"\"Provides on-demand cloud computing platforms and API's to individuals, \n",
    "    companies, and governments, on a metered pay as you go basis.\"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5498356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill in a least two items from each of the suggested categories. \n",
    "\n",
    "# TODO: Create at least one category that is not listed and add two items to that category. \n",
    "\n",
    "# List allows for future updates to all_items, using next cell\n",
    "list_entries = [\n",
    "    # AI and Machine Learning\n",
    "    ListItem(\n",
    "        \"Apache Spark's MLlib\",\n",
    "        'https://spark.apache.org/mllib/',\n",
    "        'AI and Machine Learning',\n",
    "        \"\"\"MLlib is Apache Spark's scalable machine learning library. Ease of use. Usable in Java, Scala, Python, and R.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'H2O',\n",
    "        'https://www.h2o.ai/',\n",
    "        'AI and Machine Learning',\n",
    "        \"\"\"H2O.ai is an advanced AI Cloud Platform designed to simplify and accelerate making, operating and innovating with AI in any environment.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'Tensorflow',\n",
    "        'https://www.tensorflow.org/',\n",
    "        'AI and Machine Learning',\n",
    "        \"\"\"TensorFlow is a free and open-source software library for machine learning and artificial intelligence.\"\"\"\n",
    "    ),\n",
    "\n",
    "    # Batch Processing\n",
    "    ListItem(\n",
    "        'Apache Beam',\n",
    "        'https://beam.apache.org/',\n",
    "        'Batch Processing',\n",
    "        \"\"\"Apache Beam is an open source unified programming model to define and execute data processing pipelines, including ETL, batch and stream processing\"\"\"\n",
    "    ),\n",
    "    \n",
    "     ListItem(\n",
    "        'Apache Spark',\n",
    "        'https://spark.apache.org/',\n",
    "        'Batch Processing',\n",
    "        \"\"\"Apache Spark is an open-source unified analytics engine for large-scale data processing. Spark provides an interface for programming entire clusters with implicit data parallelism and fault tolerance.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'Dask',\n",
    "        'https://dask.org/',\n",
    "        'Batch Processing',\n",
    "        \"\"\"Dask is an open-source flexible parallel computing library written in Python for analytics\"\"\"\n",
    "    ),\n",
    "\n",
    "    # Cloud and Data Platforms\n",
    "    ListItem(\n",
    "        'Amazon Web Services',\n",
    "        'https://aws.amazon.com/',\n",
    "        'Cloud and Data Platforms',\n",
    "        \"\"\"Amazon Web Services, Inc. is a subsidiary of Amazon providing on-demand cloud computing platforms and APIs to individuals, companies, and governments, on a metered pay-as-you-go basis.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'Cloudera Data Platform',\n",
    "        'https://www.cloudera.com/products/cloudera-data-platform.html',\n",
    "        'Cloud and Data Platforms',\n",
    "        \"\"\"Clouderaâ€™s open-source data platform uses analytics and machine learning to yield insights from data through a secure connection.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'Google Cloud Platform',\n",
    "        'https://cloud.google.com/',\n",
    "        'Cloud and Data Platforms',\n",
    "        \"\"\"Google Cloud Platform, offered by Google, is a suite of cloud computing services that runs on the same infrastructure that Google uses internally for its end-user products, such as Google Search, Gmail, Google Drive, and YouTube.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'Microsoft Azure',\n",
    "        'https://azure.microsoft.com/',\n",
    "        'Cloud and Data Platforms',\n",
    "        \"\"\"Microsoft Azure, often referred to as Azure, is a cloud computing service operated by Microsoft for application management via Microsoft-managed data centers.\"\"\"\n",
    "    ),\n",
    "\n",
    "    # Container Engines and Orchestration\n",
    "    ListItem(\n",
    "        'Docker',\n",
    "        'https://www.docker.com/',\n",
    "        'Container Engines and Orchestration',\n",
    "        \"\"\"Docker is a set of platform as a service products that use OS-level virtualization to deliver software in packages called containers.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'Kubernetes',\n",
    "        'https://kubernetes.io/',\n",
    "        'Container Engines and Orchestration',\n",
    "        \"\"\"Kubernetes is an open-source container-orchestration system for automating computer application deployment, scaling, and management.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'Podman',\n",
    "        'https://podman.io/',\n",
    "        'Container Engines and Orchestration',\n",
    "        \"\"\"Podman is a daemonless, open source, Linux native tool designed to make it easy to find, run, build, share and deploy applications using Open Containers Initiative (OCI) Containers and Container Images.\"\"\"\n",
    "    ),\n",
    "\n",
    "    # Data Storage :: Block Storage\n",
    "    ListItem(\n",
    "        'Amazon EBS',\n",
    "        'https://aws.amazon.com/ebs/',\n",
    "        'Data Storage :: Block Storage',\n",
    "        \"\"\"Amazon Elastic Block Store (Amazon EBS) is an easy-to-use, scalable, high-performance block-storage service designed for Amazon Elastic Compute Cloud (Amazon EC2).\"\"\"\n",
    "    ),\n",
    "    \n",
    "    ListItem(\n",
    "        'OpenEBS',\n",
    "        'https://openebs.io/',\n",
    "        'Data Storage :: Block Storage',\n",
    "        \"\"\"OpenESB is a Java-based open-source enterprise service bus. It allows you to integrate legacy systems, external and internal partners and new development in your Business Process.\"\"\"\n",
    "    ),\n",
    "\n",
    "    # Data Storage :: Cluster Storage\n",
    "    ListItem(\n",
    "        'Ceph',\n",
    "        'https://ceph.io/en/',\n",
    "        'Data Storage :: Cluster Storage',\n",
    "        \"\"\"Ceph is an open-source software storage platform, implements object storage on a single distributed computer cluster, and provides 3-in-1 interfaces for object-, block- and file-level storage.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'Hadoop Distributed File System',\n",
    "        'https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html',\n",
    "        'Data Storage :: Cluster Storage',\n",
    "        \"\"\"The Hadoop Distributed File System ( HDFS ) is a distributed file system designed to run on commodity hardware.\"\"\"\n",
    "    ),\n",
    "\n",
    "    # Data Storage :: Object Storage\n",
    "    ListItem(\n",
    "        'Amazon S3',\n",
    "        'https://aws.amazon.com/s3/',\n",
    "        'Data Storage :: Object Storage',\n",
    "        \"\"\"Amazon S3 or Amazon Simple Storage Service is a service offered by Amazon Web Services that provides scalable object storage through a web service interface.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'Minio',\n",
    "        'https://min.io/',\n",
    "        'Data Storage :: Object Storage',\n",
    "        \"\"\"MinIO is a High Performance Object Storage that is API compatible with Amazon S3 cloud storage service. It can handle unstructured data such as photos, videos, log files, backups, and container images with the maximum supported object size of 5TB.\"\"\"\n",
    "    ),\n",
    "\n",
    "    # Data Transfer Tools\n",
    "    ListItem(\n",
    "        'Apache Sqoop',\n",
    "        'https://sqoop.apache.org/',\n",
    "        'Data Transfer Tools',\n",
    "        \"\"\"Sqoop is a command-line interface application for transferring data between relational databases and Hadoop. The Apache Sqoop project was retired in June 2021 and moved to the Apache Attic.\"\"\"\n",
    "    ),\n",
    "\n",
    "    # Full-Text Search\n",
    "    ListItem(\n",
    "        'Apache Solr',\n",
    "        'https://solr.apache.org/',\n",
    "        'Full-Text Search',\n",
    "        \"\"\"Solr is an open-source enterprise-search platform, written in Java. Its major features include full-text search, hit highlighting, faceted search, real-time indexing, dynamic clustering, database integration, NoSQL features and rich document handling.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'Elasticsearch',\n",
    "        'https://www.elastic.co/elasticsearch/',\n",
    "        'Full-Text Search',\n",
    "        \"\"\"Elasticsearch is a search engine based on the Lucene library. It provides a distributed, multitenant-capable full-text search engine with an HTTP web interface and schema-free JSON documents.\"\"\"\n",
    "    ),\n",
    "\n",
    "    # Interactive Query\n",
    "    ListItem(\n",
    "        'Apache Hive',\n",
    "        'https://hive.apache.org/',\n",
    "        'Interactive Query',\n",
    "        \"\"\"Apache Hive is a data warehouse software project built on top of Apache Hadoop for providing data query and analysis. Hive gives an SQL-like interface to query data stored in various databases and file systems that integrate with Hadoop.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'Google Big Query',\n",
    "        'https://cloud.google.com/bigquery',\n",
    "        'Interactive Query',\n",
    "        \"\"\"BigQuery is a fully-managed, serverless data warehouse that enables scalable analysis over petabytes of data. It is a Platform as a Service that supports querying using ANSI SQL. It also has built-in machine learning capabilities.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'Spark SQL',\n",
    "        'https://spark.apache.org/sql/',\n",
    "        'Interactive Query',\n",
    "        \"\"\"Spark SQL is a Spark module for structured data processing. It provides a programming abstraction called DataFrames and can also act as a distributed SQL query engine.\"\"\"\n",
    "    ),\n",
    "\n",
    "    # Message Queues\n",
    "    ListItem(\n",
    "        'Apache Kafka',\n",
    "        'https://kafka.apache.org/',\n",
    "        'Message Queues',\n",
    "        \"\"\"Apache Kafka is an open-source framework implementation of a software bus using stream-processing. The project aims to provide a unified, high-throughput, low-latency platform for handling real-time data feeds.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'RabbitMQ',\n",
    "        'https://www.rabbitmq.com/',\n",
    "        'Message Queues',\n",
    "        \"\"\"RabbitMQ is an open-source message-broker software that originally implemented the Advanced Message Queuing Protocol and has since been extended with a plug-in architecture to support Streaming Text Oriented Messaging Protocol, MQ Telemetry Transport, and other protocols.\"\"\"\n",
    "    ),\n",
    "\n",
    "    # NoSQL :: Document Databases\n",
    "    ListItem(\n",
    "        'CouchDB',\n",
    "        'https://couchdb.apache.org/',\n",
    "        'NoSQL :: Document Databases',\n",
    "        \"\"\"Apache CouchDB is an open-source document-oriented NoSQL database, implemented in Erlang. CouchDB uses multiple formats and protocols to store, transfer, and process its data. It uses JSON to store data, JavaScript as its query language using MapReduce, and HTTP for an API.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'Google Firestore',\n",
    "        'https://cloud.google.com/firestore',\n",
    "        'NoSQL :: Document Databases',\n",
    "        \"\"\"Firebase is a platform developed by Google for creating mobile and web applications. It allows you to run sophisticated ACID transactions against your document data.\"\"\"\n",
    "    ),\n",
    "    \n",
    "    ListItem(\n",
    "        'MongoDB',\n",
    "        'https://www.mongodb.com/atlas',\n",
    "        'NoSQL :: Document Databases',\n",
    "        \"\"\"MongoDB is a source-available cross-platform document-oriented database program. Classified as a NoSQL database program, MongoDB uses JSON-like documents with optional schemas.\"\"\"\n",
    "    ),\n",
    "\n",
    "    # NoSQL :: Graph Databases\n",
    "    ListItem(\n",
    "        'DGraph',\n",
    "        'https://dgraph.io/',\n",
    "        'NoSQL :: Graph Databases',\n",
    "        \"\"\"Dgraph is a open-source graph database management system. Dgraph uses Raft for shard replication and a custom transactional protocol for snapshot-isolated cross-shard transactions.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'Neo4j',\n",
    "        'https://neo4j.com/product/neo4j-graph-database/',\n",
    "        'NoSQL :: Graph Databases',\n",
    "        \"\"\"Neo4j is a graph database management system developed by Neo4j, Inc. Described by its developers as an ACID-compliant transactional database with native graph storage and processing,\"\"\"\n",
    "    ),\n",
    "\n",
    "    # NoSQL :: Key-Value Databases\n",
    "    ListItem(\n",
    "        'Amazon DynamoDB',\n",
    "        'https://aws.amazon.com/dynamodb/',\n",
    "        'NoSQL :: Key-Value Databases',\n",
    "        \"\"\"Amazon DynamoDB is a fully managed proprietary NoSQL database service that supports keyâ€“value and document data structures and is offered by Amazon.com as part of the Amazon Web Services portfolio.\"\"\"\n",
    "    ),\n",
    "\n",
    "    # NoSQL :: Time-Series Databases\n",
    "    ListItem(\n",
    "        'OpenTSDB',\n",
    "        'http://opentsdb.net/',\n",
    "        'NoSQL :: Time-Series Databases',\n",
    "        \"\"\"OpenTSDB is a distributed, scalable Time Series Database (TSDB) written on top of HBase. OpenTSDB was written to address a common need: store, index and serve metrics collected from computer systems at a large scale, and make this data easily accessible and graphable.\"\"\"\n",
    "    ),\n",
    "\n",
    "    # Serverless Functions\n",
    "    ListItem(\n",
    "        'AWS Lambda',\n",
    "        'https://aws.amazon.com/lambda/',\n",
    "        'Serverless Functions',\n",
    "        \"\"\"AWS Lambda is an event-driven, serverless computing platform provided by Amazon as a part of Amazon Web Services. It is a computing service that runs code in response to events and automatically manages the computing resources required by that code.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'OpenFaaS',\n",
    "        'https://www.openfaas.com/',\n",
    "        'Serverless Functions',\n",
    "        \"\"\"OpenFaaS is an open source serverless function engine where users can publish, run, and manage functions on Kubernetes clusters.\"\"\"\n",
    "    ),\n",
    "\n",
    "    # Stream Processing\n",
    "    ListItem(\n",
    "        'Apache Storm',\n",
    "        'https://storm.apache.org/',\n",
    "        'Stream Processing',\n",
    "        \"\"\"Apache Storm is an open-source distributed stream processing computation framework written predominantly in the Clojure programming language.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'Google Dataflow',\n",
    "        'https://cloud.google.com/dataflow',\n",
    "        'Stream Processing',\n",
    "        \"\"\"Google Cloud Dataflow is a fully managed service for executing Apache Beam pipelines within the Google Cloud Platform ecosystem.\"\"\"\n",
    "    ),\n",
    "\n",
    "    # Version Control Systems\n",
    "    ListItem(\n",
    "        'Data Version Control',\n",
    "        'https://dvc.org/',\n",
    "        'Version Control Systems',\n",
    "        \"\"\"DVC is an open-source version control system for machine learning projects that lets you define your pipeline regarless of the language used.\"\"\"\n",
    "    ),\n",
    "    \n",
    "    ListItem(\n",
    "        'Git LFS',\n",
    "        'https://git-lfs.github.com/',\n",
    "        'Version Control Systems',\n",
    "        \"\"\"Git Large File Storage (LFS) is an open-source project that allows you to version large files with Git.\"\"\"\n",
    "    ),\n",
    "\n",
    "    # Visualization Frameworks\n",
    "    ListItem(\n",
    "        'Apache Superset',\n",
    "        'https://superset.apache.org/',\n",
    "        'Visualization Frameworks',\n",
    "        \"\"\"Apache Superset is an open-source software cloud-native application for data exploration and data visualization able to handle data at petabyte scale.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'Redash',\n",
    "        'https://redash.io/',\n",
    "        'Visualization Frameworks',\n",
    "        \"\"\"Redash is an open-source tool for teams to query, visualize and collaborate.\"\"\"\n",
    "    ),\n",
    "\n",
    "    # Workflow Engine\n",
    "    ListItem(\n",
    "        'Apache Airflow',\n",
    "        'https://airflow.apache.org/',\n",
    "        'Workflow Engine',\n",
    "        \"\"\"Apache Airflow is an open-source workflow management platform for data engineering pipelines.\"\"\"\n",
    "    ),\n",
    "\n",
    "    ListItem(\n",
    "        'Google Cloud Composer',\n",
    "        'https://cloud.google.com/composer',\n",
    "        'Workflow Engine',\n",
    "        \"\"\"Cloud Composer is a managed workflow automation tool that is built on Apache Airflow. It's used to author, schedule, and monitor software development pipelines across data centers.\"\"\"\n",
    "    ),\n",
    "    \n",
    "    ListItem(\n",
    "        'Oozie',\n",
    "        'https://oozie.apache.org/',\n",
    "        'Workflow Engine',\n",
    "        \"\"\"Apache Oozie is a server-based workflow scheduling system to manage Hadoop jobs. Workflows in Oozie are defined as a collection of control flow and action nodes in a directed acyclic graph.\"\"\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17e287df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon Web Services already in all_items\n",
      "Update? (Y/N)Y\n"
     ]
    }
   ],
   "source": [
    "items = [item.name for item in all_items]\n",
    "\n",
    "# Adds each element to all_items\n",
    "for entry in list_entries:\n",
    "    if entry.name in items:\n",
    "        print(f'{entry.name} already in all_items')\n",
    "        \n",
    "        # If element name already exists, offers to update in all_items\n",
    "        if input('Update? (Y/N)').upper() == 'Y':\n",
    "            outdated = next((item for item in all_items if item.name == entry.name), None)\n",
    "            all_items.remove(outdated)\n",
    "            all_items.add(entry)\n",
    "\n",
    "    else:\n",
    "        all_items.add(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fa9d69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
