# DSC-400-Page

This page includes exercises from DSC400.

With the cost of data storage consistently decreasing, data volumes are increasing, and organizations 
are no longer forced to only store the bare minimum data. The exercises in this page examine the technology 
required to analyze and process Big Data. Topics include: Hadoop/MapReduce, Spark/RDD, Spark/Storm Streaming, 
TensorFlow, Keras Deep Learning, Kubernetes, and Docker. It would help if you have an understanding of Data Mining 
and Data Wrangling for Data Science to understand the exercises.
